# MVP 1.1: TechnickÃ¡ SEO AnalÃ½za â€“ AutomatizaÄnÃ­ Blueprint

## VstupnÃ­ dokument: seo-learning-guide-v2.docx (14 fÃ¡zÃ­, Macro Consulting)

---

## 1. MapovÃ¡nÃ­ fÃ¡zÃ­ na automatizaci

### Legenda automatizovatelnosti
- ğŸŸ¢ **PLNÄš AUTOMATIZOVATELNÃ‰** â€“ robot zvlÃ¡dne bez lidskÃ©ho zÃ¡sahu
- ğŸŸ¡ **ÄŒÃSTEÄŒNÄš AUTOMATIZOVATELNÃ‰** â€“ robot sbÃ­rÃ¡ data, AI interpretuje, ale vyÅ¾aduje kontext
- ğŸ”´ **MANUÃLNÃ / VYÅ½ADUJE PÅ˜ÃSTUPY** â€“ nelze automatizovat bez externÃ­ch credentials
- âšª **MIMO MVP 1.1** â€“ odloÅ¾eno na pozdÄ›jÅ¡Ã­ verzi

### PÅ™ehled fÃ¡zÃ­

| FÃ¡ze | NÃ¡zev | Auto | MVP 1.1 | NÃ¡hrada za Screaming Frog |
|------|-------|------|---------|--------------------------|
| 0 | PÅ™Ã­prava a sbÄ›r kontextu | ğŸŸ¡ | âœ… ÄŒÃ¡steÄnÄ› | Wappalyzer API + site: query |
| 1 | Crawl webu | ğŸŸ¢ | âœ… | Playwright crawler + cheerio |
| 2 | Indexace a viditelnost | ğŸŸ¡ | âœ… Bez GSC | Crawl data + robots.txt + sitemap parse |
| 3 | Architektura a internÃ­ linking | ğŸŸ¢ | âœ… | Crawl graph analysis |
| 4 | Rychlost a vÃ½kon (CWV) | ğŸŸ¢ | âœ… | PageSpeed Insights API (free) |
| 5 | MobilnÃ­ pouÅ¾itelnost | ğŸŸ¢ | âœ… | PSI API (mobile strategy) + viewport check |
| 6 | HTTPS a bezpeÄnost | ğŸŸ¢ | âœ… | Crawl data (SSL, redirects, mixed content) |
| 7 | StrukturovanÃ¡ data | ğŸŸ¢ | âœ… | HTML parse â†’ JSON-LD/Microdata extraction |
| 8 | Obsah a on-page prvky | ğŸŸ¢ | âœ… | Crawl data (titles, metas, H1, images, word count) |
| 9 | JavaScript SEO | ğŸŸ¡ | âœ… ZÃ¡kladnÃ­ | Playwright: raw HTML vs rendered DOM diff |
| 10 | Crawl Budget a log analÃ½za | ğŸ”´ | âšª | VyÅ¾aduje server logy â€“ mimo MVP |
| 11 | AEO a GEO | ğŸŸ¡ | âœ… ÄŒÃ¡steÄnÄ› | robots.txt AI bot check + llms.txt + schema check |
| 12 | MezinÃ¡rodnÃ­ SEO | ğŸŸ¢ | âœ… Pokud hreflang | Crawl data (hreflang parsing) |
| 13 | Kompilace a prioritizace | ğŸŸ¡ | âœ… | AI (Claude) generuje Impact/Effort + report |

---

## 2. TechnickÃ¡ architektura Job pipeline

### CelkovÃ½ flow

```
User klikne "Spustit analÃ½zu"
    â”‚
    â–¼
[API Route] VytvoÅ™Ã­ job record v Supabase (status: queued)
    â”‚
    â–¼
[Railway Worker] Pickup job z queue
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: PÅ˜ÃPRAVA (FÃ¡ze 0)                      â”‚
â”‚  - Resolve domain â†’ base URL                    â”‚
â”‚  - Fetch robots.txt â†’ parse rules               â”‚
â”‚  - Fetch sitemap.xml â†’ collect known URLs        â”‚
â”‚  - Tech stack detection (Wappalyzer-like)        â”‚
â”‚  - Progress: 5%                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: CRAWL (FÃ¡ze 1)                         â”‚
â”‚  - BFS crawl z base URL (Playwright + cheerio)   â”‚
â”‚  - Respektuj robots.txt                          â”‚
â”‚  - Max depth = user config (default 3)           â”‚
â”‚  - Max pages = user config (default 100)         â”‚
â”‚  - Max 5 concurrent requests (politeness)        â”‚
â”‚  - JS rendering pro sample (kaÅ¾dÃ¡ 10. strÃ¡nka)   â”‚
â”‚  - Collect per page:                             â”‚
â”‚    - URL, status code, redirect chain            â”‚
â”‚    - Title, meta description, H1-H6             â”‚
â”‚    - Canonical, meta robots, hreflang            â”‚
â”‚    - Internal/external links + anchors           â”‚
â”‚    - Images (src, alt, size)                     â”‚
â”‚    - Word count, JSON-LD structured data         â”‚
â”‚    - Response time                               â”‚
â”‚  - Progress: 5% â†’ 50% (incremental)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: PAGESPEED (FÃ¡ze 4+5)                   â”‚
â”‚  - PageSpeed Insights API pro sample strÃ¡nek     â”‚
â”‚  - Homepage + top 5 nejdÅ¯leÅ¾itÄ›jÅ¡Ã­ch (by inlinks)â”‚
â”‚  - Mobile + Desktop strategy                     â”‚
â”‚  - LCP, INP, CLS, TTFB, performance score       â”‚
â”‚  - Progress: 50% â†’ 60%                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: ANALYSIS (FÃ¡ze 2,3,6,7,8,9,11,12)     â”‚
â”‚  - AnalyzÃ©ry bÄ›Å¾Ã­ paralelnÄ› nad crawl daty:      â”‚
â”‚                                                  â”‚
â”‚  [indexability]    robots.txt conflicts,          â”‚
â”‚                    noindex vs sitemap,            â”‚
â”‚                    canonical issues               â”‚
â”‚                                                  â”‚
â”‚  [architecture]   click depth, orphan detection, â”‚
â”‚                    internal link distribution,    â”‚
â”‚                    URL structure quality          â”‚
â”‚                                                  â”‚
â”‚  [security]       HTTPS, mixed content,          â”‚
â”‚                    redirect chains/loops,         â”‚
â”‚                    HSTS header                    â”‚
â”‚                                                  â”‚
â”‚  [structured-data] JSON-LD extraction,           â”‚
â”‚                     schema type coverage,         â”‚
â”‚                     validation errors             â”‚
â”‚                                                  â”‚
â”‚  [on-page]        titles, metas, H1 structure,   â”‚
â”‚                    duplicate content detection,   â”‚
â”‚                    thin content, image issues     â”‚
â”‚                                                  â”‚
â”‚  [js-seo]         raw vs rendered DOM diff        â”‚
â”‚                    (for JS-heavy sites)           â”‚
â”‚                                                  â”‚
â”‚  [aeo-geo]        AI bot access in robots.txt,   â”‚
â”‚                    llms.txt presence,             â”‚
â”‚                    answer-first format score,     â”‚
â”‚                    E-E-A-T signals check          â”‚
â”‚                                                  â”‚
â”‚  [international]  hreflang validation             â”‚
â”‚                    (if detected)                  â”‚
â”‚                                                  â”‚
â”‚  - Progress: 60% â†’ 80%                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: AI COMPILATION (FÃ¡ze 13)               â”‚
â”‚  - Claude Sonnet dostane:                        â”‚
â”‚    - VÅ¡echny issues ze vÅ¡ech analyzÃ©rÅ¯           â”‚
â”‚    - Crawl statistiky                            â”‚
â”‚    - User custom instructions / client context   â”‚
â”‚  - Generuje:                                     â”‚
â”‚    - Executive summary                           â”‚
â”‚    - Impact/Effort scoring pro kaÅ¾dÃ½ issue       â”‚
â”‚    - Quadrant assignment (Quick Win / Major /    â”‚
â”‚      Fill-in / Time Waster)                      â”‚
â”‚    - PrioritizovanÃ½ akÄnÃ­ plÃ¡n                   â”‚
â”‚    - AI recommendations text                     â”‚
â”‚  - Progress: 80% â†’ 95%                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: REPORT ASSEMBLY                         â”‚
â”‚  - Compile final TechnicalAuditResult JSON       â”‚
â”‚  - Store in Supabase jobs.result                 â”‚
â”‚  - Status: completed                             â”‚
â”‚  - Progress: 100%                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ÄŒasovÃ½ odhad (100 strÃ¡nek, depth 3)

| Step | OdhadovanÃ½ Äas | Bottleneck |
|------|----------------|------------|
| Preparation | 5-10s | Sitemap fetch |
| Crawl | 3-8 min | Politeness delay (5 concurrent, 200ms gap) |
| PageSpeed | 30-60s | API rate limit (1 req/s) |
| Analysis | 10-30s | CPU-bound, paralelnÃ­ |
| AI Compilation | 15-30s | Claude API latency |
| Report Assembly | <5s | DB write |
| **TOTAL** | **~5-10 min** | Crawl je dominantnÃ­ |

---

## 3. DetailnÃ­ specifikace analyzÃ©rÅ¯

### 3.1 Crawler (Step 2) â€“ jÃ¡dro systÃ©mu

**Technologie:** Playwright (headless Chromium) + cheerio (fast HTML parse)

**Strategie:**
- BFS (breadth-first) crawl z homepage
- Playwright pro JS rendering (sample: kaÅ¾dÃ¡ 10. strÃ¡nka, nebo pokud tech stack = React/Vue/Angular/Next.js)
- Cheerio pro statickÃ© strÃ¡nky (rychlejÅ¡Ã­, mÃ©nÄ› resources)
- Respektuje robots.txt (parsovanÃ½ v Step 1)
- User-Agent: custom ("MacroBot/1.0" + kontaktnÃ­ email)

**Per-page data model:**
```typescript
interface CrawledPage {
  url: string;
  finalUrl: string;                    // po redirectech
  statusCode: number;
  redirectChain: RedirectHop[];        // [{from, to, statusCode}]
  responseTimeMs: number;
  contentType: string;
  contentLength: number;

  // Head
  title: string | null;
  metaDescription: string | null;
  canonical: string | null;
  metaRobots: string | null;          // "noindex, nofollow" etc
  xRobotsTag: string | null;          // from HTTP header
  viewport: string | null;
  hreflang: HreflangEntry[];          // [{lang, href}]
  maxImagePreview: string | null;

  // Content
  h1: string[];
  h2: string[];
  h3: string[];
  wordCount: number;
  rawHtmlLength: number;

  // Links
  internalLinks: LinkData[];           // [{href, anchorText, isNofollow}]
  externalLinks: LinkData[];
  brokenLinks: string[];               // 4xx/5xx targets found during crawl

  // Images
  images: ImageData[];                 // [{src, alt, width, height, sizeKb, format}]

  // Structured Data
  jsonLd: object[];                    // parsed JSON-LD blocks
  microdata: object[];                 // parsed microdata

  // JS rendering (if applicable)
  jsRenderDiff: {
    contentDiffPercent: number;        // how much content differs raw vs rendered
    linksOnlyInRendered: number;       // links visible only after JS
  } | null;

  // Timing
  crawledAt: string;                   // ISO timestamp
  crawlDepth: number;                  // clicks from homepage
}
```

### 3.2 AnalyzÃ©ry (Step 4) â€“ modulÃ¡rnÃ­ checky

KaÅ¾dÃ½ analyzÃ©r je samostatnÃ½ modul. Vstup = pole CrawledPage + metadata (robots.txt, sitemap URLs). VÃ½stup = pole Issue[].

**indexability-analyzer:**
- Noindex strÃ¡nky v sitemapÄ› â†’ CRITICAL
- Canonical na 404/noindex/redirect â†’ CRITICAL
- Canonical Å™etÄ›zenÃ­ â†’ WARNING
- Sitemap obsahuje non-200 URLs â†’ WARNING
- ChybÄ›jÃ­cÃ­ self-referencing canonical â†’ WARNING
- Conflicting directives (noindex + sitemap) â†’ CRITICAL
- robots.txt blokuje dÅ¯leÅ¾itÃ© sekce â†’ CRITICAL

**architecture-analyzer:**
- Click depth > 4 na dÅ¯leÅ¾itÃ½ch strÃ¡nkÃ¡ch â†’ WARNING
- Click depth > 5 â†’ CRITICAL
- Orphan pages (v sitemapÄ› ale ne v crawl grafu) â†’ WARNING
- StrÃ¡nky s < 3 internÃ­ch odkazÅ¯ â†’ INFO
- URL s parametry bez canonical â†’ WARNING
- Non-lowercase URLs â†’ INFO
- URLs > 115 znakÅ¯ â†’ INFO

**performance-analyzer:**
- LCP > 4.0s â†’ CRITICAL, > 2.5s â†’ WARNING
- INP > 500ms â†’ CRITICAL, > 200ms â†’ WARNING
- CLS > 0.25 â†’ CRITICAL, > 0.1 â†’ WARNING
- TTFB > 600ms â†’ WARNING, > 200ms â†’ INFO
- Performance score < 50 â†’ CRITICAL, < 90 â†’ WARNING

**security-analyzer:**
- HTTP (ne HTTPS) â†’ CRITICAL
- Mixed content â†’ WARNING
- Missing HSTS â†’ INFO
- Redirect chain > 2 hops â†’ WARNING
- Redirect loop â†’ CRITICAL
- 302 where 301 expected â†’ INFO

**structured-data-analyzer:**
- Missing Organization schema â†’ WARNING
- Missing BreadcrumbList â†’ WARNING
- Missing Article/BlogPosting on blog posts â†’ INFO
- FAQ pages without FAQPage schema â†’ INFO
- E-commerce without Product schema â†’ WARNING
- JSON-LD validation errors â†’ WARNING

**on-page-analyzer:**
- Missing title â†’ CRITICAL
- Duplicate titles â†’ WARNING
- Title > 60 chars â†’ INFO
- Title < 30 chars â†’ WARNING
- Missing meta description â†’ WARNING
- Duplicate meta descriptions â†’ WARNING
- Missing H1 â†’ CRITICAL
- Multiple H1 â†’ WARNING
- H1 duplicates title â†’ INFO
- Thin content (< 300 words on content pages) â†’ WARNING
- Images missing alt text â†’ WARNING
- Images > 150KB without optimization â†’ INFO
- Missing max-image-preview:large â†’ INFO

**aeo-geo-analyzer:**
- GPTBot blocked in robots.txt â†’ WARNING (s kontextem)
- ClaudeBot blocked â†’ WARNING
- PerplexityBot blocked â†’ WARNING
- Missing llms.txt â†’ INFO (recommendation)
- Missing author schema on articles â†’ INFO
- Missing "O nÃ¡s" page signals â†’ INFO
- No external citations in content â†’ INFO

**international-analyzer:**
- Non-reciprocal hreflang â†’ CRITICAL
- Hreflang pointing to 404/redirect â†’ CRITICAL
- Missing x-default â†’ WARNING
- Invalid language codes â†’ WARNING

### 3.3 AI Compilation (Step 5) â€“ Claude prompt

```
System: You are a senior SEO analyst at a digital marketing agency.
You receive structured crawl data and issue lists from an automated 
technical SEO audit tool. Your job is to:

1. Write an executive summary (3-5 sentences) of the site's overall 
   technical SEO health
2. Score each issue on Impact (1-5) and Effort (1-5) based on:
   - Impact: scope (global template vs single page), commercial 
     relevance, AI influence
   - Effort: dev capacity needed, content workload, risk level
3. Assign each issue to a quadrant:
   - Quick Win (high impact, low effort)
   - Major Project (high impact, high effort)
   - Fill-in (low impact, low effort)
   - Time Waster (low impact, high effort)
4. Generate a prioritized action plan with sprint assignments:
   - Sprint 1: All Quick Wins + top 3 Critical Major Projects
   - Sprint 2: Remaining Major Projects
   - Backlog: Fill-ins
   - Discarded: Time Wasters
5. Write actionable recommendations in Czech language

User context (if provided): {custom_instructions}
Site tech stack: {detected_tech_stack}
Total pages crawled: {count}
```

---

## 4. Co NENÃ v MVP 1.1 (a proÄ)

| Feature | DÅ¯vod vylouÄenÃ­ | Kdy pÅ™idat |
|---------|----------------|------------|
| GSC API integrace | VyÅ¾aduje OAuth + klientskÃ© pÅ™Ã­stupy | MVP 1.2 nebo 1.3 |
| GA4 API integrace | VyÅ¾aduje OAuth + klientskÃ© pÅ™Ã­stupy | MVP 1.2 nebo 1.3 |
| Server log analÃ½za (FÃ¡ze 10) | VyÅ¾aduje pÅ™Ã­stup k serveru klienta | BudoucÃ­, volitelnÃ½ |
| PlnÃ½ JS rendering vÅ¡ech strÃ¡nek | PomalÃ½ + resource heavy | Optimalizace v 1.2 |
| PDF analÃ½za (FÃ¡ze 8.8) | Nice to have, ne core | 1.2 |
| Video indexace check (8.7) | SpecifickÃ©, ne pro vÅ¡echny weby | 1.2 |
| Shopping GPT check (11.6) | Jen pro e-shopy | 1.2 |
| ManuÃ¡lnÃ­ AI citace test (11.8) | VyÅ¾aduje API pÅ™Ã­stupy k AI sluÅ¾bÃ¡m | BudoucÃ­ modul |
| Export do Google Doc | Google API integrace | Po Google Workspace integraci |
| Duplicate content (near-duplicate) | VÃ½poÄetnÄ› nÃ¡roÄnÃ½ (simhash/minhash) | 1.2 |

---

## 5. User-facing parametry (Job launcher UI)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TECHNICKÃ SEO ANALÃZA                          â”‚
â”‚                                                  â”‚
â”‚  Klient: [dropdown â€“ vybranÃ½ klient]            â”‚
â”‚                                                  â”‚
â”‚  DomÃ©na *                                        â”‚
â”‚  [https://www.example.cz          ]             â”‚
â”‚                                                  â”‚
â”‚  Hloubka crawlu                                  â”‚
â”‚  [3 â–¼]  (1-5, default 3)                        â”‚
â”‚                                                  â”‚
â”‚  MaximÃ¡lnÃ­ poÄet strÃ¡nek                         â”‚
â”‚  [100 â–¼]  (10 / 50 / 100 / 250 / 500)           â”‚
â”‚                                                  â”‚
â”‚  PoznÃ¡mky a kontext (volitelnÃ©)                  â”‚
â”‚  [                                    ]          â”‚
â”‚  [  E-shop na Shopify, cÃ­lÃ­ na CZ trh,]         â”‚
â”‚  [  hlavnÃ­ produkt jsou boty...       ]          â”‚
â”‚  [                                    ]          â”‚
â”‚                                                  â”‚
â”‚  [ â–¶ Spustit analÃ½zu ]                           â”‚
â”‚                                                  â”‚
â”‚  âš¡ OdhadovanÃ½ Äas: ~5-10 min pro 100 strÃ¡nek   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. VÃ½stupnÃ­ report (UI struktura)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š TECHNICKÃ SEO ANALÃZA: example.cz           â”‚
â”‚  Klient: Firma XYZ | Datum: 28.2.2026           â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Score   â”‚ â”‚ Criticalâ”‚ â”‚ Warning â”‚ â”‚ Info   â”‚â”‚
â”‚  â”‚  72/100 â”‚ â”‚    5    â”‚ â”‚   12    â”‚ â”‚   8    â”‚â”‚
â”‚  â”‚ ğŸŸ¡      â”‚ â”‚ ğŸ”´      â”‚ â”‚ ğŸŸ¡      â”‚ â”‚ ğŸ”µ    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                  â”‚
â”‚  ğŸ“ Executive Summary                            â”‚
â”‚  Web example.cz vykazuje solidnÃ­ technickÃ½ zÃ¡kladâ”‚
â”‚  ale mÃ¡ kritickÃ© problÃ©my s kanonizacÃ­ a...      â”‚
â”‚                                                  â”‚
â”‚  â”€â”€â”€ KATEGORIE â”€â”€â”€                               â”‚
â”‚                                                  â”‚
â”‚  â–¼ Indexace a viditelnost (3 critical, 2 warning)â”‚
â”‚    ğŸ”´ 15 URL v sitemapÄ› mÃ¡ noindex tag           â”‚
â”‚    ğŸ”´ Canonical Å™etÄ›zenÃ­ na produktovÃ½ch str.    â”‚
â”‚    ğŸ”´ robots.txt blokuje /api/products/          â”‚
â”‚    ğŸŸ¡ ChybÃ­ self-referencing canonical na 45 str.â”‚
â”‚    ğŸŸ¡ 8 URL v sitemapÄ› vracÃ­ 301                 â”‚
â”‚                                                  â”‚
â”‚  â–¼ Rychlost a vÃ½kon (1 critical, 3 warning)     â”‚
â”‚  â–¼ Architektura (0 critical, 4 warning)         â”‚
â”‚  â–¼ On-page (1 critical, 3 warning, 5 info)      â”‚
â”‚  â–¼ StrukturovanÃ¡ data (0 critical, 2 warning)   â”‚
â”‚  â–¼ BezpeÄnost (0 critical, 1 warning)           â”‚
â”‚  â–¼ AEO / GEO (0 critical, 3 info)              â”‚
â”‚                                                  â”‚
â”‚  â”€â”€â”€ AKÄŒNÃ PLÃN â”€â”€â”€                              â”‚
â”‚                                                  â”‚
â”‚  Sprint 1 (Quick Wins + Top Critical):           â”‚
â”‚  â˜ Opravit robots.txt blokaci /api/products/    â”‚
â”‚  â˜ Odstranit noindex z 15 produktovÃ½ch strÃ¡nek  â”‚
â”‚  â˜ Implementovat llms.txt                        â”‚
â”‚  ...                                             â”‚
â”‚                                                  â”‚
â”‚  [ğŸ“„ Export PDF]  [ğŸ“‹ KopÃ­rovat tikety]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Aktualizace steering docs

### libraries.md â€“ novÃ© typy
- CrawledPage interface
- Analyzer output interfaces
- TechnicalAuditResult rozÅ¡Ã­Å™eno o quadrant assignments

### tech.md â€“ novÃ© worker dependencies
- playwright (headless Chromium)
- cheerio (HTML parsing)
- robots-parser
- xml2js (sitemap parsing)
- lighthouse (volitelnÄ›, v budoucnu mÃ­sto PSI API)

### decisions.md â€“ novÃ© ADR
- ADR-006: Playwright + cheerio hybrid crawler (ne Screaming Frog API)
- ADR-007: PageSpeed Insights API mÃ­sto lokÃ¡lnÃ­ho Lighthouse (MVP)
- ADR-008: Sample JS rendering (ne full render) pro performance

---

## 8. OmezenÃ­ MVP 1.1 (disclaimer pro uÅ¾ivatele)

Report by mÄ›l obsahovat sekci "OmezenÃ­ tohoto auditu":
- Bez pÅ™Ã­stupu ke GSC â€“ nelze ovÄ›Å™it reÃ¡lnÃ½ stav indexace Google
- Bez pÅ™Ã­stupu k server logÅ¯m â€“ nelze analyzovat crawl budget
- JS rendering na vzorku â€“ nÄ›kterÃ© JS issues mohou bÃ½t pÅ™ehlÃ©dnuty
- Near-duplicate detection nenÃ­ implementovÃ¡n
- PageSpeed data jsou laboratornÃ­ (lab), ne polnÃ­ (field/CrUX)

Tato omezenÃ­ zmizÃ­ postupnÄ› s integracÃ­ GSC API (MVP 1.2/1.3).
